---
title: "Introduction to the pif package: Estimating Potential Impact and Population Attributable Fractions"
author: Dalia Camacho García Formentí \& Rodrigo Zepeda Tello 
output: rmarkdown::html_vignette
bibliography: Referencias.bib
csl: american-journal-of-epidemiology.csl
vignette: >
  %\VignetteIndexEntry{Introduction to the pif package: Estimating Potential Impact and Population Attributable Fractions}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
 
```{r, echo=FALSE, message= FALSE, warning=FALSE}
require(pif)
require(ggplot2)
set.seed(3256)
```

##Introduction

The Potential Impact Fraction (PIF) quantifies the contribution of exposure to a risk-factor to either morbidity (or mortality). In particular, it compares the observed burden of disease (or death) with a hypothetical no-exposure scenario (also called theoretical-minimum-risk-exposure scenario). PIF is usually defined [@murray2003comparative; @vander2004estimating] for some exposure $X$ with parametrical Relative Risk $RR(X;\theta)$ with parameter $\theta$, and counterfactual function $\textrm{cft}$ as:

\begin{equation}
\textrm{PIF} = \frac{\sum_{i=1}^m P_i \cdot RR(X_i;\theta) - \sum_{i=1}^m P_i \cdot RR(\textrm{cft}(X_i);\theta)}{\sum_{i=1}^m P_i \cdot RR(X_i;\theta)}
\end{equation}

if $X$ is categorical (discrete) and:

\begin{equation}
\textrm{PIF} = \frac{\int_{\mathcal{X}} RR(X;\theta)f(X)dX - \int_{\mathcal{X}} RR\big(\textrm{cft}(X);\theta \big)f(X)dX}{\int_{\mathcal{X}} RR(X;\theta)f(X)dX,}
\end{equation}

if $X$ is continuous. In the aforementioned equations $P_i$ represents the probability of $X$ being at the $i$-th category and $f$ the density function of $X$. 

Some examples of Relative Risk functions include [@barendregt2010categorical]: 

1. Linear: $R(X;\theta) = 1 + \theta X$,
2. Exponential: $R(X;\theta) = e^{\theta X}$.
3. Quadratic: $R(X;\theta_1, \theta_2) = 1 + \theta_1 X + \theta_2 X^2$

We remark that in both cases, when the counterfactual is that of the "theoretical-minimum-risk-exposure" the PIF is equivalent to the Population Attributable Fraction (PAF) defined as:

\begin{equation}
\textrm{PAF} = 
\begin{cases}
\frac{\sum_{i=1}^m P_i \cdot RR(X_i;\theta) - 1}{\sum_{i=1}^m P_i \cdot RR(X_i;\theta)} & \textrm{if } X \textrm{ is categorical}, \\ \\
\frac{\int_{\mathcal{X}} RR(X;\theta)f(X)dX - 1}{\int_{\mathcal{X}} RR(X;\theta)f(X)dX} & \textrm{if } X \textrm{ is continuous}. \\
\end{cases}
\end{equation}

<!--Although the PIF has been widely used, the selection process for a distribution of the exposure values in the continuous case tends to be unclear. This can lead to a number of issues and miscalculations as has been discussed elsewhere .  -->

In this document we present the ``pif`` package which allows the estimation of both PIF and PAF when using information from cross-sectional data. This document is structured as follows:

1. We present a ["quick start"](#quick-start) guide if you really cannot resist the urge of using the package. 
2. We briefly discuss the [methods involved](#methods) and their implementations.
3. We dive into [deeper examples concerning more advanced options](#advanced-examples) of our package so you are able to use it like a pro.
4. We show some [common error messages](#common-error-messages) and how to fix them. 


<!--Since miscalculations of the PIF concerning the selection of an incorrect distribution for exposure values arise more often in the continuous case than in the discrete one, our study focuses on the case of continuous exposure values with continuous relative risk functions. However the method suggested can be used for discrete exposure values or discrete relative risk functions. Examples of these cases will be given in the last section as well.-->

## Quick start

The basic ingredients for using the package are:

1. A Relative Risk function $RR$ which might depend on a parameter $\theta$ (usually it does).
2. A sample $X_{(n)}$ of $n$ exposure values (or if it is not available, at least estimated mean $m$ and variance $s$ of the exposure). 
3. A Maximum Likelihood Estimator $\hat{\theta}$ of $\theta$. 
4. A function $cft$ that transforms the observed exposure into that of a counterfactual scenario.

If you have those you are ready to start with our examples which include: [sample of the exposure with continuous Relative Risks](#continuous-rr-example-ozone-exposure), [sample of the exposure with  categorical Relative Risks](#discrete-rr-example-tobacco-consumption), [only mean and variance of exposure with continuous Relative Risks](#incomplete-data-continuous-rr-example-systolic-blood-pressure), and [only mean and variance of exposure with categorical Relative Risks](#incomplete-data-categorical-rr-example-body-mass-index). 

### Continuous RR example: Ozone Exposure

This example aims to estimate the PIF and PAF of Ozone on children's lung growth. The ``airquality`` dataset (included in R) has information on Ozone levels for New York City.

```{r}
require(datasets)
ozone_exposure  <- na.omit(airquality$Ozone) 
```

Furthermore, assume normalized sampling weights for Ozone exposure are given by:
```{r}
sampling_weights <- c(rep(1/232, 58), rep(0.75/58, 58))
```

Suppose the Relative Risk of reduced lung growth given exposure is defined by:
\begin{equation}
RR(X;\theta) = e^{\theta X}
\end{equation}
where $\theta$ is estimated by $\hat{\theta} = 0.11$ with variance $\sigma_\theta^2 = 0.0025$:

```{r}
thetahat <- 0.17
thetavar <- 0.00025
```

We can code the Relative Risk function as:
```{r}
rr <- function(X, theta){ exp(theta*X/5) }
```

Notice that the parameters should be $X$ and $\theta$ **in that order**. Never forget this! Now we are ready to estimate the Population Attributable Fraction:
```{r}
paf(X = ozone_exposure, thetahat = thetahat, rr = rr, weights = sampling_weights)
```

We can estimate the Potential Impact Fraction provided we have a counterfactual. Let's assume we want to scale exposure to Ozone in 50\% and reduce it by $1$. The counterfactual function is thus:

```{r}
cft <- function(X){0.5*X - 1}
```

Notice that the counterfactual is solely a function of the exposure $X$. We are now ready to compute the Potential Impact Fraction:
```{r}
pif(X = ozone_exposure, thetahat = thetahat, rr = rr, cft = cft, weights = sampling_weights)
```
   
No study is complete without confidence intervals. Let's calculate the confidence intervals for both PAF and PIF. 

```{r }
paf.confidence(X = ozone_exposure, thetahat = thetahat, thetavar = thetavar, rr = rr, weights = sampling_weights)
```
    
```{r}
pif.confidence(X = ozone_exposure, thetahat = thetahat, thetavar = thetavar, rr = rr, cft = cft, weights = sampling_weights)
```     

Several plots are available to enrich our study. We can plot the effect of the counterfactual:

```{r, fig.width=7, fig.height=4}
counterfactual.plot(X = ozone_exposure, cft = cft, weights = sampling_weights)
```

We can also conduct several sensitivity analysis: 

1. To see how the PAF changes as $\theta$ changes between $0$ and $1/\pi$ (notice that it is nonlinear)

```{r, fig.width=7, fig.height=4}
paf.plot(X = ozone_exposure, thetalow = 0, thetaup = 1/pi, rr = rr, weights = sampling_weights)
```

same plot is available for the PIF:
```{r, fig.width=7, fig.height=4}
pif.plot(X = ozone_exposure, thetalow = 0, thetaup = 1/pi, rr = rr, cft = cft, weights = sampling_weights)
```

2. To evaluate the robustness of the PAF (*i.e.* would it change much had we a different sample?)

```{r, fig.width=7, fig.height=4}
paf.sensitivity(X = ozone_exposure, thetahat = thetahat, rr = rr, weights = sampling_weights)
```

the same can be done for the PIF:

```{r, fig.width=7, fig.height=4}
pif.sensitivity(X = ozone_exposure, thetahat = thetahat, rr = rr, weights = sampling_weights)
```

3. A sensitivity analysis on how PIF changes as the parameters of the counterfactual change. Notice that in order to use this function we need to specify in the definition of counterfactual the parameters involved (maximum 2):

```{r, fig.width=7, fig.height=4}
#Change the counterfactual function to specify the parameters involved
cft_sensitivity <- function(X, a, b){a*X - b}
```

We can also specify the range at which we will change the counterfactual's parameters. For this example, let's change $b$ from $0$ to $2$ and $a$ from $0.5$ to $0.75$.

```{r, fig.width=7, fig.height=4}
#Do the sensitivity analysis
pif.heatmap(X = ozone_exposure, thetahat = thetahat, rr = rr, cft = cft_sensitivity, mina = 0.5, maxa = 0.75, minb = 0, maxb = 1, weights = sampling_weights)
```

### Discrete RR example: Tobacco consumption

In this example we will compute the PIF and PAF of tobacco consumption over oesophageal cancer. For that purpose we will use the ``esoph`` dataset included in R. 

```{r}
require(datasets)
tobacco_consumption <- as.matrix(esoph$tobgp)
```

This variable contains categorical information on the number of grams/dat of tobacco consumed. Assume the Relative Risk function is given by:
\begin{equation}
RR(X;\theta) = 
\begin{cases}
\theta_1 & \textrm{ if  consumption is } 0-9g/day,\\
\theta_2 & \textrm{ if  consumption is } 10-19,   \\
\theta_3 & \textrm{ if  consumption is } 20-29,   \\
\theta_4 & \textrm{ if  consumption is } 30_{+}.  \\
\end{cases}
\end{equation}
with estimators $\hat{\theta_1} = 1$, $\hat{\theta_2} = 1.59$, $\hat{\theta_3} = 2.57$, $\hat{\theta_4} = 4.11$ of the respective $\theta$s. This can be programmed in R as follows:

```{r}
#Thetas
thetahat <- c(1, 1.59, 2.57, 4.11)

#Relative Risk
rr       <- function(X, theta){
  
  #Create empty vector to fill with RR's
  r_risk <- rep(NA, nrow(X))
  
  #Select by cases
  r_risk[which(X == "0-9g/day")] <- theta[1]
  r_risk[which(X == "10-19")]    <- theta[2]
  r_risk[which(X == "20-29")]    <- theta[3]
  r_risk[which(X == "30+")]      <- theta[4]
  
  return(r_risk)
}
```

Notice that the Relative Risk assumes the exposure $X$ is a matrix with each row representing an individual. We can estimate the Population Attributable Fraction:

```{r}
paf(tobacco_consumption, thetahat, rr)
```

Consider the counterfactual of every smoker of the categories $20-29$ and $30_{+}$ to the $10-19$ category. That can be coded as:
```{r}
cft <- function(X){
  
  #Create empty matrix to fill with RR's
  new_tobacco <- matrix(NA, nrow = nrow(X), ncol = 1)
  
  #Select by cases
  new_tobacco[which(X == "0-9g/day")] <- "0-9g/day"  #These remain
  new_tobacco[which(X == "10-19")]    <- "10-19"     #the same
  new_tobacco[which(X == "20-29")]    <- "10-19"
  new_tobacco[which(X == "30+")]      <- "10-19"
  
  return(new_tobacco)
}
```

the Potential Impact Fraction is given by:
```{r}
pif(tobacco_consumption, thetahat, rr, cft)
```

In order to compute confidence intervals, assume the following covariance matrix of $\hat{\theta}$:
\begin{equation}
\Sigma_{\theta} = \left( 
\begin{array}{cccc}
0.119 & 0 & 0 & 0     \\
0 & 0.041 & 0 & 0 \\
0 & 0 & 0.001 & 0 \\
0 & 0 & 0 & 0.093
\end{array}
\right)
\end{equation}

which in R is:
```{r}
thetavar <- diag(c(0.119, 0.041, 0.001, 0.093))
```

The confidence interval for the PAF is:
```{r}
paf.confidence(X = tobacco_consumption, thetahat = thetahat, thetavar = thetavar, rr = rr,  confidence_method = "bootstrap")
```

The confidence interval for the Impact Fraction is given by:
```{r}
pif.confidence(X = tobacco_consumption, thetahat = thetahat, thetavar = thetavar, rr = rr, cft = cft, confidence_method = "bootstrap")
```

We remark that ``"bootstrap"`` is the only ``confidence_method`` designed for categorical relative risks. 

The ``counterfactual.plot`` function produces an appropriate plot for the discrete exposure:
```{r, fig.width=7, fig.height=4}
counterfactual.plot(tobacco_consumption, cft)
```

A sensitivity analysis to evaluate both PAF and PIF's robustness is available:
```{r, fig.width=7, fig.height=4}
paf.sensitivity(tobacco_consumption, thetahat, rr)
```

```{r, fig.width=7, fig.height=4}
pif.sensitivity(tobacco_consumption, thetahat, rr, cft = cft)
```


### Incomplete data Continuous RR example: Systolic Blood Pressure

Consider the following data on Systolic Blood Pressure (SBP) in females aged 30-44 by world region from [@lawes2006blood]:

```{r}
sbp <- data.frame("Region"   = c("Afr D", "Afr E", "Amr A", "Amr B", "Amr D",
                                 "Emr B", "Emr D", "Eur A", "Eur B", "Eur C",
                                 "Sear B", "Sear D", "Wpr A", "Wpr B"), 
                  "SBP_mean" = c(123, 121, 114, 115, 117, 126, 121, 
                                 122, 122, 125, 120, 117, 120, 115),
                  "SBP_sd"   = c(20, 13, 14, 15, 15, 15, 15, 
                                 15, 16, 17, 15, 14, 15, 16))
```

Furthermore, consider the Relative Risk of mortality given SBP as:
\begin{equation}
RR(SBP; \theta) = 1 + \theta (SBP - 115)^2
\end{equation}
with $\hat{\theta} = 0.71$ estimator of $\theta$ with estimated variance $s^2 = 0.002$.
In R this is given by:

```{r}
thetahat <- 0.71
thetavar <- 0.002

#Notice that the theoretical minimum risk value is 115 and not 0
rr       <- function(X, theta){ theta*(X - 115)^2/121 + 1} 
```

In this case, only mean and standard deviation information is available for each region. Terrible calamity! However the ``pif`` package is prepared for such cases and the ``"approximate"`` method is in order. For example, let's calculate the Population Attributable Fraction for the ``"AFR E"`` region:

```{r}
#Get mean and variance
afr_mean <- subset(sbp, Region == "Afr E")$SBP_mean
afr_var  <- subset(sbp, Region == "Afr E")$SBP_sd^2 #Notice that variance is enormous!

#Calculate paf using approximate method
paf(X = afr_mean, thetahat = thetahat, rr = rr, method = "approximate", Xvar = afr_var, check_rr = FALSE)
```

We can also compute confidence intervals:

```{r}
paf.confidence(X = afr_mean, thetahat = thetahat,  thetavar = thetavar, rr = rr, method = "approximate", Xvar = afr_var, check_rr = FALSE)
```

A counterfactual of reducing the overall blood pressure in 5 is given by:
```{r}
cft <- function(X){X - 5}
```

And the Potential Impact Fraction translates into:

```{r}
pif(X = afr_mean, thetahat = thetahat, rr = rr, cft = cft, method = "approximate", Xvar = afr_var, check_rr = FALSE)
```

with confidence interval:
```{r}
pif.confidence(X = afr_mean, thetahat = thetahat, rr = rr, cft = cft, method = "approximate", Xvar = afr_var, check_rr = FALSE, thetavar = thetavar)
```

We can plot how PAF (and PIF) estimates change as functions of $\theta$:
```{r, fig.width=7, fig.height=4}
paf.plot(X = afr_mean, thetalow = 0, thetaup = 6, rr = rr, method = "approximate", Xvar = afr_var,  check_rr = FALSE)
```

```{r, fig.width=7, fig.height=4}
pif.plot(X = afr_mean, thetalow = 0, thetaup = 6, rr = rr, cft = cft, method = "approximate", Xvar = afr_var,  check_rr = FALSE)
```

### Incomplete data Categorical RR example: Body Mass Index

<div style = "background-color: red;">
Create a function that approximates differentiably the counterfactual function in an arbitrary fashion.
</div>

## Methods

A broader definition of the Population Impact Fraction (which includes both cases presented in the [Introduction](#introduction)) is given by:
\begin{equation}
\textrm{PIF} =   1 - \frac{E_{X}\left[RR\big(\textrm{cft}(X);\theta\big)\right] }{E_{X}\left[RR\big(X; \theta\big)\right]}.
\end{equation}
where $\textrm{cft}(X)$ denotes the counterfactual transform of the exposure $X$, $RR$ the relative risk function with parameter $\theta$. Note that PAF is a special case of the $\textrm{PIF}$ when the counterfactual corresponds to $X$ being the theoretical minimum risk exposure. We have developed three methods of estimation: [empirical](#the-empirical-potential-impact-fraction), [kernel](#kernel-based-potential-impact-fraction) and [approximate](#approximate-empirical-potential-impact-fraction). 


### The Empirical Potential Impact Fraction

Let the Relative Risk function $RR:\mathcal{X} \times \Theta \to I \subset (0,\infty)$ be either convex, concave or Lipschitz continuous as a function of $\theta$. For $ X_1, X_2, \dots, X_n $ a random sample of $X\in\mathcal{X}\subset\mathbb{R}^p$ with normalized sampling weights  $w_1, w_2, \dots, w_n$ and $\hat{\theta} \in \Theta \subset \mathbb{R}^q$ a consistent estimator of  $\theta$ with $\Theta, \mathcal{X}, I$ compact sets. We define the functions:

\begin{equation}
\hat{\mu}_n^{\textrm{obs}}(\theta) = \sum\limits_{i=1}^{n}  w_i RR\big( X_i; \theta \big), \quad \textrm{and} \quad \hat{\mu}_n^{\textrm{cft}}(\theta) = \sum\limits_{i=1}^{n}  w_i RR\big( \textrm{cft}(X_i); \theta \big),
\end{equation}
then:

\begin{equation}\label{pafestimate}
\widehat{\textrm{PIF}} = 1 - \dfrac{\hat{\mu}_n^{\textrm{cft}}(\hat{\theta})}{\hat{\mu}_n^{\textrm{obs}}(\hat{\theta})}, \qquad \textrm{and} \qquad \widehat{\textrm{PAF}} = 1 - \dfrac{1}{\hat{\mu}_n^{\textrm{obs}}(\hat{\theta})} 
\end{equation}
are consistent estimators of the Potential Impact Fraction ($\textrm{PIF}$) and the Population Attributable Fraction ($\textrm{PAF}$) respectively. 


### Kernel Based Potential Impact Fraction

Define the Relative Risk $RR:\mathcal{X} \times \Theta \to I \subset (0,\infty)$ (the additional hypothesis used for the [empirical method](#the-empirical-potential-impact-fraction) are not necessary).  Let $\hat{f}$ denote a kernel density obtained from the random sample of $X\in\mathcal{X}\subset\mathbb{R}^p$. Let $\hat{\theta} \in \Theta \subset \mathbb{R}^q$ be a consistent estimator of  $\theta$. We define the functions:

\begin{equation}
\hat{\nu}_n^{\textrm{obs}}(\theta) = \int\limits_{\mathbb{R}^p}  RR( x; \theta)\hat{f}(x), \quad \textrm{and} \quad \hat{\nu}_n^{\textrm{cft}}(\theta) = \int\limits_{\mathbb{R}^p}  RR\big( \textrm{cft}(x); \theta\big)\hat{f}(x)dx,
\end{equation}
then:

\begin{equation}
\widehat{\textrm{PIF}} = 1 - \frac{\hat{\nu}_n^{\textrm{cft}}(\hat{\theta})}{\hat{\nu}_n^{\textrm{obs}}(\hat{\theta})}
\end{equation}
is a consistent estimator of the Potential Impact Fraction ($\textrm{PIF}$).

### Approximate Empirical Potential Impact Fraction

Sometimes researchers do not have a random sample of the exposure $X$; nevertheless, they posess $m$, $s^2$ estimators of the exposure's mean and variance (respectively). Furthermore, assume that for each $\theta$ the Relative Risk function $RR(\cdot, \theta)$ has a second order Taylor Expansion for all $X$ and that the counter-factual function is twice differentiable. An approximate point estimate for PIF is given by the Laplace approximation:

\begin{equation}
\widehat{\textrm{PIF}}= 1-\frac{RR(\textrm{cft}(m),\theta) + \frac{1}{2}\left(\frac{\partial^2RR}{\partial \textrm{cft}^2}\cdot\left(\frac{d \textrm{cft}}{d X}\right)^2 + \frac{\partial RR}{\partial \textrm{cft}}\cdot \frac{d ^2 \textrm{cft}}{d X^2}\right)\Big|_m s^2}{RR(m;\hat{\theta})+\frac{1}{2} \frac{\partial^2 RR(X;\hat{\theta})}{\partial X^2}|_{m}s^2}.
\end{equation}

The approximate method solely requires the sample mean and variance $m$, $s^2$ and not the whole sample. If the sample is available, the other methods should be prefered.  

### Methods in code

All methods have been coded in the ``method`` option of the functions ``paf``, ``pif`` and related. That is: we can estimate the PIF by different methods specifying the type:

```{r}
#Data
set.seed(2374)
X        <- rlnorm(100)
rr       <- function(X, theta){theta*X + 1}
cft      <- function(X){sqrt(X)}
thetahat <- 0.1943

#Empirical
pif(X, thetahat, rr, cft, method = "empirical")

#Kernel
#pif(X, thetahat, rr, cft, method = "kernel")

#Approximate
pif(mean(X), thetahat, rr, cft, method = "approximate", Xvar = var(X))
```

Note that for the approximate method the correct input is mean and variance of X. If no method is specified in ``pif`` (`pif(X, thetahat, rr, cft)`) the ``"empirical"`` is chosen.


### Confidence Intervals

<div style = "background-color: red"> Dalia  please complete this section from your appendix</div>

<!--
To get the confidence intervals of the PAF we must calculate the variance of PAF (or of a transformation of the PAF), notice that uncertainty comes from two sources: the exposure data $X$ and the Relative Risk parameter $\theta$. Since we have a sample of the exposure values and the point estimate and confidence intervals of parameter $\theta$ we use conditional probability:

\begin{equation}\label{conditioningvar}
\textrm{Var} \left(A \right)  = E_{B} \left[ \textrm{Var} \left( A \left. \right| B \right) \right] + \textrm{Var}_{B} \left[ E\left( A \left. \right| B\right)  \right],
\end{equation}
conditioning on $\theta$.

Four different approaches to get confidence intervals were taken. 

1. The linear method, that calculates the confidence interval for the linearization of PAF.
2. The loglinear method in which the confidence interval for $g(\hat{\theta}) = \text{ln}\left(1 - \widehat{PAF}(\hat{\theta})\right)=\hat{\mu}_n(\theta)$ is calculated and then transformed to get PAF confidence interval.
3. The inverse method consists on estimating the confidence intervals for $\hat{\mu}_n(\theta)$ and then inverting.
4. The one to one method estimates of conditional confidence intervals for $R_O(\theta)$  (as in the inverse method) are calculated and applied to the lower and upper bounds of $\theta$ to obtain a confidence interval[@bar1999confidence].

All confidence intervals are constructed assuming asymptotic normality. 

###Approximate empirical method
In the previous section estimates were calculated assuming one has a sample of exposure levels, however this might not be the case. It may occur that the only available information is the sample-mean $\hat{\mu}$ and sample-variance $\hat{\sigma}^2$  of the exposure levels. To avoid errors that arise from distribution mis-specification we propose using the estimator:

\begin{equation}
\widehat{PAF}= 1-\frac{1}{R(\hat{\mu};\hat{\theta})+\frac{1}{2} \frac{\partial^2 R(x;\hat{\theta})}{\partial x^2}|_{\hat{\mu}}\hat{\sigma}^2}\label{approxpaf}
\end{equation}

To calculate confidence intervals using the approximate point estimate the variance was calculated considering the linearization of PAF. (The resulting confidence intervals are different than those for the empirical method using linear confidence intervals.)
-->

## Advanced examples

This section is concerned with more advanced options of the `pif` package functions. We first analyze [how to choose an estimation method](#deciding-on-the-estimation-method); secondly, we show [how to choose a confidence interval](#deciding-on-the-confidence-interval), finally we show [how to work with the plots](#working-with-the-plots). 

### Deciding on the estimation method

[The previous section](#methods) discussed the three estimation methods used in the package. In this section we discuss some advanced options as well as how to choose the method

#### Method choosing 

- If a complete sample of the exposure is available, the [empirical](#the-empirical-potential-impact-fraction), or [kernel](#kernel-based-potential-impact-fraction) methods are valid choices. The [approximate method](#approximate-empirical-potential-impact-fraction) should be discarded as there is no need to approximate the result from [empirical](#the-empirical-potential-impact-fraction) if the sample is available.  The [empirical](#the-empirical-potential-impact-fraction) method works for linear, polynomial and exponential Relative Risks: it rests on the assumption that the function $RR$ of the Relative Risk is convex, concave or Lipschitz (which almost all functions we have encountered in this setting are). Functions that do not comply with this characteristics and have a continuous exposure can be estimated via the [kernel](#kernel-based-potential-impact-fraction) method which works for all functions of interest in applications. 

- If only mean and variance of the exposure are known, the [approximate method](#approximate-empirical-potential-impact-fraction)  is the only choice.

The following diagram summarizes when to choose which method:

<div style = "background-color: red"> CREATE DIAGRAM </div> 


#### Kernel

A kernel density is an approximation to the probability density function of a random variable constructed from the variable's sample. For instance the following image shows the real density for a Normally distributed random variable with mean $0$ and variance $1$ as well as the kernel approximation to said density from a sample of size 45. 

```{r, fig.width=7, fig.height=4, echo = FALSE}

#Get a random variable distributed normally
X              <- rnorm(45)
Y              <- seq(-3,3, length.out = 100)
real_density   <- data.frame("Density" = dnorm(Y), "Axis" = Y)

#Approximate via kernel
kernel_density <- data.frame("Density" = density(X)$y, "Axis" = density(X)$x)

#Show the density
ggplot() + 
  geom_line(aes(x = Axis, y = Density, color = "Real density"), data = real_density) + 
  geom_line(aes(x = Axis, y = Density, color = "Kernel density"), data = kernel_density) +
  scale_color_manual("Type", values = c("Real density" = "purple",
                                        "Kernel density" = "tomato3")) +
  theme_classic() + xlab("X") + ggtitle("Real and approximate density of normal distribution from sample of size 45")

```

There are several kernel types that provide different forms of approximation. For example, consider the follwing sample:

```{r}
set.seed(46)
X <- rlnorm(25)
```

Whose density can be approximated via kernels:
```{r, fig.width=7, fig.height=4, echo = FALSE}

#Check kernel types
kernels         <- c("gaussian", "epanechnikov", "rectangular", 
                     "triangular", "biweight", "cosine", "optcosine")
color_k         <- rainbow(length(kernels))
names(color_k)  <- kernels 

#Data frame
kdata           <- data.frame(matrix(NA, 
                                     ncol = length(kernels) + 1, 
                                     nrow = 250))
colnames(kdata) <- c("X", kernels)
kdata$X         <- seq(-3, 8, length.out = 250)


#Create kernel densities
for(ktype in kernels){
    kernel_density  <- density(X, kernel = ktype)
    mat_approximate <- approx(kernel_density$x, kernel_density$y, 
                              kdata$X, rule = 2)
    kdata[ ,ktype]  <- mat_approximate$y
}

#Create plot
kplot  <- ggplot(kdata, aes(x = X)) 
for(ktype in kernels){
  kplot <- kplot + geom_line(aes_string(y = ktype, color = factor(ktype)))
}
kplot + scale_color_manual("Kernel type", values = color_k) + theme_classic() +
  ylab("Density")
  

```

Notice that different kernels have different approximations to the sample's density.  Henceforth, if we were to estimate the Impact Fraction, different values would result from different kernels:

```{r}
thetahat <- 1
thetavar <- 0.1
rr       <- function(X, theta){theta*X + 1}
cft      <- function(X){X/2}

#Rectangular kernel
pif.confidence(X, thetahat, rr, cft = cft, method = "kernel", ktype = "gaussian", thetavar = thetavar)

#Gaussian kernel
pif.confidence(X, thetahat, rr, cft = cft, method = "kernel", ktype = "rectangular", thetavar = thetavar)

```

Additional kernel options include bandwith, adjustment, and number of interpolation points. These options are taken directly from the ``density`` function. 

```{r}
pif.confidence(X, thetahat, rr, cft = cft, method = "kernel", ktype = "rectangular", bw = "nrd", adjust = 2, n = 1000, thetavar = thetavar)
```



#### Approximate

As stated previously, the [approximate method](#approximate-empirical-potential-impact-fraction) should only be utilized if the only information known to the researcher is sample mean and variance but **the sample is not available**. The approximate method works with numerical derivatives from using `numDeriv` package and as such options for derivatives are available. Consider the theoretical function:

```{r}
rr <- function(X, theta){ theta*sin(exp(X-1))^2 + 1}
```

Assume the following information is available of $X$:
```{r}
Xmean    <- 10
Xvar     <- 0.25
thetahat <- 1
```

The approximate PAF is given by:
```{r}
paf(Xmean, thetahat, rr, Xvar = Xvar, method = "approximate")
```

Additional options can be changed to improve the derivative method:
```{r}
paf(Xmean, thetahat, rr, Xvar = Xvar, 
    method = "approximate", 
    deriv.method = "complex", 
    deriv.method.args = list(eps=1.e-6, d=0.01, zero.tol=1.e-8, r=4, v=2, show.details=TRUE))
```


### Deciding on the confidence interval 

<div style = "background-color: red">Dalia could you help me here? </div>

#### Linear and loglinear

#### Bootstrap

#### One 2 one

#### Inverse

#### Force min

#### Comparison

<div style = "background-color: red"> CREATE A PLOT COMPARING THE PRECISION AND CONFIDENCE OF THE INTERVALS?? </div>

### Working with the plots




The R package pif was developed to calculate the PAF and the PIF via the empirical and approximate methods, however an option to estimate the distribution of the exposure values using kernels is also available. Confidence intervals for the PAF and the PIF using different approaches have been programmed. Along with the confidence intervals a sensitivity analysis can be done when a sample of exposure values is available. The package pif also offers the posibility to plot the PAF and the PIF for a sample of exposure values (or point estimate) and different values of $\theta$, when $\theta$ is unidimensional. Other visual aids are heatmaps for counterfactuals, one can visually compare what would occur in different counterfactual scenarios. 

In this section we show how to use the package pif through examples.
###Potential Attributable Fraction (PAF)
```{r}
# devtools::install_github("INSP-RH/pif")
library(pif)
library(ggplot2)
```


Consider an exponential relative risk function $RR(X;\theta)=e^{\theta X}$, where the parameter $\theta$ is estimated by $\hat{\theta} = 0.11$, and consider a random sample of the exposure values $X$.

```{r}
set.seed(242)
rr       <- function(x, theta){exp(theta*x)}
thetahat <- 0.11
X        <- rnorm(1000, 9, 3)
```

We use our package to estimate the population atributable fraction via the empirical method:
```{r}
paf(X = X, thetahat = thetahat, rr = rr)
```

The PAF calculated above considers the sampling weights of the exposure values to be equal. In case the observed exposure values have different sampling weights, the PAF is calculated by:

```{r}
weights <- c(rep(1/1500, 500), rep(2/1500, 500))
paf(X = X, thetahat = thetahat, rr = rr, weights = weights)
```

The default method is empirical, but it can be changed to kernel method when the exposure values for one observation are unidimensional and there are no covariates.

```{r}
paf(X = X, thetahat = thetahat, rr = rr, method = "kernel")
```

where the kernel-type, adjustment and bandwidth can be changed:

```{r}
paf(X = X, thetahat = thetahat, rr = rr, method = "kernel", ktype = "cosine", adjust = 0.6)
```

Confidence intervals for the PAF can be calculated. For example if the variance of $\hat{\theta}$ is $0.0025$:

```{r}
thetavar <- 0.0025
paf.confidence(X = X, thetahat = thetahat, thetavar = thetavar, rr = rr)
```

The inverse method to calculate confidence intervals for the PAF is the inverse method, however other methods have been implemented. In particular, because $e^{\theta X}$ is convex, we can use the one to one ("one2one") method by specifying the lower and upper bounds of $\hat{\theta}$ confidence interval. If the confidence interval for $\hat{\theta}$ is given by $(0.09, 0.13)$ then the confidence interval with the one to one method is calculated as:

```{r}
thetalow <- 0.09
thetaup  <- 0.13
paf.confidence(X, thetahat = thetahat, thetalow = thetalow, thetaup = thetaup, rr = rr, confidence_method = "one2one")
```

The previous examples consider a random sample of exposure values is available, however we developed a method for estimating the PAF when only mean and variance of the exposure values are known. 

```{r}
Xmean <- mean(X)
Xvar  <- var(X)
paf(X = Xmean, Xvar = Xvar, thetahat = thetahat, rr = rr, method = "approximate")
```

###Potential Impact Fraction (PIF)

Consider the same relative risk function, $\hat{\theta}$ and sample of exposure values as before. We are now interested in estimating the effects of a counterfactual scenario, which is not necessarily the no-exposure counterfactual. As an example, consider a transformation of X given by: $T(X) = aX + b$. Consider $a = 0.5$ and $b = -1$, to estimate the PIF first we code the counterfactual function:

```{r}
cft <- function(X){0.5*X - 1}
```

Then we estimate the PIF via the empirical method:
```{r}
pif(X = X, thetahat = thetahat, rr = rr, cft = cft)
```

The PIF can also be calculated by estimating a distribution for exposure values using a kernel:

```{r}
pif(X = X, thetahat = thetahat, rr = rr, cft = cft, method = "kernel", ktype = "gaussian")
```

###Plots and visual aids

####Plot for different values of $\theta$

The command "pif.plot" allows us to analyze how the potential impact fraction varies as the values of $\theta$ changes:

```{r fig.width=7, fig.height=4}
thetalow <- 0.09
thetaup <- 0.13
pif.plot(X = X, thetalow = thetalow, thetaup = thetaup, rr = rr, cft = cft)
```

####Sensitivity Analysis

The command pif.sensitivity allows us to analyze how our estimates for the potential impact fraction would vary if we excluded some part of the exposure sample, the usage would be the following:

```{r, eval=FALSE}
pif.sensitivity(X = X,thetahat = thetahat, rr = rr, cft = cft)
```

The default sensitivity analysis removes up to a hundred observations, and takes fifty samples in each case. This is possible to modify if one wishes to remove at most fifty observations and take twenty samples in this case the code should be:

```{r fig.width=7, fig.height=4}
pif.sensitivity(X = X,thetahat = thetahat, rr = rr, cft = cft, nsim = 20, mremove = 50)
```

The title can also be modified, for example if one is doing the sensitivity analysis for the PAF instead of the PIF, the title could be "Sensitivity Analysis for Population Attributable Fraction"

```{r fig.width=7, fig.height=4}
pif.sensitivity(X = X,thetahat = thetahat, rr = rr, title = "Sensitivity Analysis for Population Attributable Fraction", nsim = 20, mremove = 50)
```

The sensitivity analysis can only be performed when a sample of exposure values is available, therefore no sensitivity analysis can be made for the PIF when only mean and variance of exposure is known.

####Heatmap for counterfactuals

To evaluate different counterfactual scenarios a heatmap is a useful tool, for one can have an idea of the possible outcomes from different counterfactuals. The counterfactual scenarios analyzed by default are those with the counterfactual function $\text{cft}(X)=aX+b$, where $a\in(0.01, 0.99)$ and $b\in(-1,0)$. These counterfactual scenarios can be graphed as:

```{r fig.width=7, fig.height=4}
pif.heatmap(X=X, thetahat = thetahat, rr = rr)
```

However other counterfactual scenarios can be represented. 
For example, the same counterfactual function can be analyzed for different values of $a$ and $b$. If $a\in(0.5, 1)$ and $b\in(-3,-1)$ 

```{r fig.width=7, fig.height=4}
mina <- 0.5
maxa <- 1
minb <- -3
maxb <- -1
pif.heatmap(X=X, thetahat = thetahat, rr = rr, mina = mina, maxa = maxa, minb = minb, nmesh = 5)
```

Not only linear counterfactuals can be shown in the heatmap. For the counterfactual $log(aX + b)$, with $a\in (0.5, 1)$ and $b\in(-0.2,0)$:

```{r fig.width=7, fig.height=4}
cft <- function(X, a, b){log(a*X+b)}

mina <- 0.5
maxa <- 1
minb <- -0.2
maxb <- 0

pif.heatmap(X=X, thetahat = thetahat, rr = rr, mina = mina, maxa = maxa, minb = minb, cft = cft, nmesh = 5)
```

The title, axis names, colors, and the grid can also be changed 

```{r fig.width=7, fig.height=4}

pif.heatmap(X=X, thetahat = thetahat, rr = rr,
                           nmesh = 5, title = "PIF under different counterfactuals",
                           xlab = "Variable a", ylab = "Variable b",
                           palette = rainbow(5))
```

The following example is to show how the package can be used to calculate the PAF and the PIF of lung cancer due to tobacco exposure.

###Calculating de PAF of lung cancer due to tobacco exposure
####Empirical method
Imagine one wishes to calculate the PAF of lung cancer given to tobacco exposure, and a sample $X$ (with equal sampling weights) of the exposure levels is provided. Assume the relative risk function is $e^{\theta X}$, where $\hat{\theta}=0.2$.

```{r}
#Suppose this is the random sample:
X        <- rnorm(500, 3, 0.1)
thetahat <- 0.2

#Create the Relative Risk function
RR       <- function(X,theta){exp(X*theta)}

#Calculate the PAF
PAF      <- pif(X, thetahat = thetahat, rr = RR)
PAF
```

Therefore the potential attributable fraction is approximately `r I(round(PAF,2))` , and `r I(round(PAF,4)*100)`\% of lung cancer cases are attributable to exposure. 

The sample of exposure levels might have outliers that drastically change the resulting PAF, therefore the package offers the possibility to make a sensitivity analysis.

```{r fig.width=7, fig.height=4}
pif.sensitivity(X, thetahat = thetahat, rr = RR, nsim = 20, mremove = 50)
```


Now assume a confidence interval for $\theta$ is provided where $\theta \in (0.1,0.3)$ is a $95\%$ confidence interval. If we're interested on knowing how PAF is going to be within this interval we can plot PAF as follows.

```{r fig.width=7, fig.height=4}
thetalow <- 0.1
thetaup <- 0.3

plot     <- pif.plot(X, thetalow = thetalow, thetaup = thetaup, rr = RR)
plot     <- plot + ggtitle(paste("PAF for lung cancer under different",
                                 "values of theta \n Empirical method"))
plot
```

From the graph it is possible to see that for this interval for theta PAF values range from an approximate `r I(round(pif(X,thetahat=thetalow,rr =RR),2))`, to `r I(round(pif(X,thetahat=thetaup,rr =RR),2))`. So between `r I(round(pif(X,thetahat=thetalow,rr =RR),4)*100)`\% and  `r I(round(pif(X,thetahat=thetaup,rr =RR),4)*100)`\% of lung cancer cases seem attributable to tobacco exposure. The $(0.25, 0.6)$ interval is not a confidence interval for PAF, because it doesn't take into account variability in the exposure values. Therefore a confidence interval for $PAF$ is required. Assuming $\theta$ has a normal distribution and confidence intervals have $95\%$ confidence and using the one to one method the resulting confidence interval for PAF is:

```{r}
paf.confidence(X, thetahat = thetahat, thetalow =  thetalow, thetaup = thetaup, rr = RR, confidence_method = "one2one")
```


Suppose having an exposure equal to zero for all individuals is unachievable, however a policy where tobacco exposure can be reduced to half can be applied. In this case the counterfactual function is $f(X)=\frac{X}{2}$. To calculate the population impact fraction we do the following:


```{r}
cft      <- function(X){X/2}
PIF      <- pif(X, thetahat = thetahat, rr = RR, cft = cft)
PIF
```

With this policy approximately `r I(round(PIF,4)*100)`\% of lung cancer cases could be reduced. 

Now imagine one wishes to consider different policies with different possible counterfactual scenarios. If these scenarios are a linear transformations of the current one a heatmap is useful. 

```{r fig.width=7, fig.height=4}
mina <- 0
maxa <- 0.8
minb <- 0
maxb <- 0
pif.heatmap(X=X, thetahat = thetahat, rr = rr,
                           mina = mina, maxa = maxa, minb = minb, nmesh = 10)
```


####Approximate method
Now assume that one wishes to calculate PAF and PIF as before, but the only information available is the mean and variance of the exposure values.

```{r}
Xmean  <- mean(X)
Xvar   <- var(X)
```

Assume one wishes to calculate PAF of lung cancer given to tobacco exposure with relative risk function is $e^{\theta X}$, where $\hat{\theta}=0.2$ just as in the previous example. But now only mean exposure ($\bar{X} =$ `r Xmean`) and variance ($s^2 =$ `r Xvar`) of the exposure are provided. In this case paf should be calculated with the approximate method.

```{r}
PAFapprox <- pif(X = Xmean, thetahat = thetahat, rr = RR,
                 method = "approximate", Xvar = Xvar)
PAFapprox
```

PAF in this case gives `r I(round(PAFapprox,2))`, and if there was no exposure   `r I(round(PAFapprox,2)*100)`\% of lung cancer cases could be avoided. 

A plot of how PAF approximate changes with different values of $\theta$ can be done also:

```{r fig.width=7, fig.height=4}

plot     <- pif.plot(Xmean, thetalow = thetalow, 
                     thetaup = thetaup, rr = RR, 
                     method = "approximate", Xvar = Xvar)
plot     <- plot + ggtitle(paste("PAF for lung cancer under different", 
                                 "values of theta \n Approximate method")) 

plot
```

Now we calculate confidence intervals for PAF when only mean and variance of exposure values from a previous study is available. We calculate the interval with the one to one method.

```{r}
PAFCI <- paf.confidence(Xmean, thetahat = thetahat, thetalow = thetalow, thetaup = thetaup,
                        rr = RR, Xvar = Xvar, method = "approximate", 
                        confidence_method = "one2one")
PAFCI
```

If we calculate the confidence interval for the whole sample using the linear method
An approximate PIF is also easily computed: 

```{r}
PIFapprox <- pif(X = Xmean, thetahat = thetahat, 
                 rr = RR, cft = cft, 
                 method = "approximate", Xvar = Xvar)
PIFapprox
```

With the policy that helps reduce tobacco exposure to half, the potential impact fraction is of `r I(round(PIFapprox,4))`. Therefore about `r I(round(PIFapprox,4)*100)`\% of lung cancer cases could be prevented with this policy.

###Examples where either the relative risk or exposure values are categorical

####Example 1: Categorical Relative Risk & Exposure
In this case the population is divided in categories: normal, overweight and obese. The relative risk function has a value of $1$ in the normal category, of $1.2$ for the overweight population, and of $1.5$ for the obese population. 
In this case the relative risk function can be defined as:  

```{r}
set.seed(18427)
X        <- sample(c("Normal","Overweight","Obese"), 100, 
                   replace = TRUE, prob = c(0.4, 0.1, 0.5))
thetahat <- c(1, 1.2, 1.5)

#Categorical relative risk function
rr <- function(X, theta){
  
  #Create return vector with default risk of 1
  r_risk <- rep(1, length(X))
  
  #Assign categorical relative risk
  r_risk[which(X == "Normal")]      <- thetahat[1]
  r_risk[which(X == "Overweight")]  <- thetahat[2]
  r_risk[which(X == "Obese")]       <- thetahat[3]
  
  return(r_risk)
}
```

The PAF using package pif is simply calculated as:
```{r}
paf(X, thetahat, rr)
```

The counterfactual scenario in which all obese people are treated and become normal can be given by:
```{r}
#Counterfactual of reducing all obesity to normality
cft <- function(X){
  X[which(X == "Obese")] <- "Normal"
  return(X)
}
```

With this the PIF is calculated as:

```{r}
pif(X, thetahat, rr, cft)

```


## References

